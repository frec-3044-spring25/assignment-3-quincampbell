---
title: "Climate Change Module"
author: 'Quinlan Campbell'
format:
  html:
    embed-resources: true
---

```{r message=FALSE}
library(tidyverse)
```

## Warm-up: Examining CO2 trends in R

- Example from <http://climate.nasa.gov/vital-signs/carbon-dioxide/>
- Raw data from <https://gml.noaa.gov/webdata/ccgg/trends/co2/co2_mm_mlo.txt>

In 1958, Dr. Charles David Keeling (1928-2005), a scientist at Scripps Institute of Oceanography, began collecting data on atmospheric CO2 concentration at the Mauna Loa Observatory located in Hawaii. This dataset allowed us to understand the degree to which climate change is human-caused through our burning of fossil fuels and release of CO2 into the atmosphere. Due to his scientific achievements, Dr. Keeling was awarded the National Medal of Science by President George W. Bush in 2002. This is the highest award for lifetime scientific achievement that can be granted in the U.S. Today, you get to analyze this same dataset, except that you have more data than was available to Dr. Keeling and his colleagues because your dataset extends up to the current time.

To read the code, you will use a new function called `read_table`.  It is similar to `read_csv` except it looks for spaces between column entries rather than commas (remember that csv stands for comma-separated values).  Others include `read_tsv`, which uses tabs to separate entries.  You can discover the separation type by putting <https://gml.noaa.gov/webdata/ccgg/trends/co2/co2_mm_mlo.txt> into your web browser and examining the file.  The code also includes an argument for comment, which denotes the character used to define a line in the file as being a comment rather than data or a header.  The file also reveals that the column headers are on lines with a comment character, so they won't be read.  You will use the argument `col_names` to define the headers manually.  Finally, `NA` values are defined by the numbers -1 and -99, so they need to be defined using the `na` argument (otherwise, they will be read as numeric values).

```{r message=FALSE}

co2 <-  read_table("https://gml.noaa.gov/webdata/ccgg/trends/co2/co2_mm_mlo.txt", 
                  comment="#",
                  col_names = c("year", "month", "decimal_date",
                                "monthly_average",
                                "deseasonalized", "days", "sd_days",
                                "unc_month_mean"),
                  na = c("-1", "-99.99"))
co2
```


```{r}
ggplot(co2, aes(x = decimal_date, y = monthly_average)) + 
  geom_line() + 
  geom_line(aes(y = deseasonalized), color = "blue") +
  labs(x = "Year", y = "CO2 concentration (ppm)")
```

**Question 1:**

Describe the overall trend in the CO2 data.

**Answer 1:**
The overall trend in the CO2 data is positive and upward; the CO2 concentration is rising fairly steadily over time.

```{r}
monthly_co2 <- co2 |>
  group_by(month) |>
  summarize(mean_co2 = mean(monthly_average, na.rm = TRUE))

ggplot(monthly_co2, aes(x = month, y = mean_co2)) +
  geom_line() +
  geom_point() +
  labs(x = "Month", y = "Mean CO2 concentration (ppm)", title = "Average Monthly CO2") 

```

**Question 2:**

How does CO2 vary within a year?  What month is it at max?  Min?  What might explain this sub-annual pattern? (you will need to write code and make a plot to answer this question)

**Answer 2:**
The average CO2 levels for a year are fairly steady for the first couple months, then increase aorund March, reach their peak around May, and then steadily drop until around late August/ early September, where they reach their lowest level. From there they slowly rise again in December, reaching levels a only little lower than January's average. My guess as to what would explain this pattern is plants are absorbing more CO2 in the warmer months, and then are absorbing far less CO2 when they're dormant for the winter.


## Global Temperature Data

Current climate change affects many aspects of the environment, with socio-economic consequences. For example, a warmer climate can allow new diseases to be introduced and persist (e.g., West Nile became established in the United States after an unusually warm winter, which allowed the mosquitoes that carry the virus to survive and spread). We are concerned not only with the actual temperature but also with the rate at which it changes. Rapid changes make it more likely that species cannot adapt and will go extinct. 

Each of the most recent years has been the warmest on record. In this section, we will analyze global mean temperature data.

Data from: <https://climate.nasa.gov/vital-signs/global-temperature/>

**Question 3:**

Describe the data set to the best of your ability, given the documentation provided. 

- Where is the data from?
- Describe the class of each column and what units it is measured in. 
- What is the difference between "global temperature" and "global temperature anomaly"? 

**Answer 3:**
This data is from NASA's Goddard Institute for Space Studies (GISS). 
The columns are:
Year: class= integer, units= years
No_Smoothing: class= numeric, units= degrees 
Lowess(5) = class= numeric, units= degrees Celcius

Global temperature is the average temperature of Earth's surface. A global temperature anomaly is the difference between an average or baseline temperature, and the one recorded.

**Question 4:**

Construct the necessary R code to import and prepare for plotting the following data set: <https://data.giss.nasa.gov/gistemp/graphs/graph_data/Global_Mean_Estimates_based_on_Land_and_Ocean_Data/graph.txt>

You'll need to determine the file's delimiter and any comments or skips. You will also need to be sure that you have column names. You will not directly use the code above to read the CO2 data, but that code provides helpful tips for reading the data.

**Answer 4:**

```{r}

temp <-  read_table("https://data.giss.nasa.gov/gistemp/graphs/graph_data/Global_Mean_Estimates_based_on_Land_and_Ocean_Data/graph.txt", 
                  comment="#",
                  col_names = c("year", "no_smoothing", "lowess_5"), 
                  skip = 5,
                  na = c("-1", "-99.99"))
```
**Question 5:**

Plot the trend in global mean temperatures over time.  Describe what you see in the plot and how you interpret the patterns you observe.

**Answer 5:**
This graph shows a mostly steady increase over time. The graph shows that from 1880 up to about 1940, the global mean temperature anomalies were negative,   meaning the temp for that year was below the baseline. From 1940 to present day, temperature anomalies have been increasingly positive, demonstarting a higher than baseline mean global temperature. 

```{r}
ggplot(temp, aes(x = year, y = no_smoothing))+
  geom_line() +
  geom_line(aes(y = lowess_5), color = "blue") +
  labs(title = "Global Mean Temperature Anomalies over Time", x ="Year", y = "Global Mean Temperature Anomalies")
```
## Evaluating the evidence for a "Pause" in warming?

The [2013 IPCC Report](https://www.ipcc.ch/pdf/assessment-report/ar5/wg1/WG1AR5_SummaryVolume_FINAL.pdf) included a tentative observation of a "much smaller increasing trend" in global mean temperatures since 1998 than was observed previously.  This led to much discussion in the media about the existence of a "Pause" or "Hiatus" in global warming rates, as well as much research looking into where the extra heat could have gone.  (Examples discussing this question include articles in [The Guardian](http://www.theguardian.com/environment/2015/jun/04/global-warming-hasnt-paused-study-finds), [BBC News](http://www.bbc.com/news/science-environment-28870988), and [Wikipedia](https://en.wikipedia.org/wiki/Global_warming_hiatus)). 

You will use rolling averages to help you explore the evidence for a pause. Since you have not been provided instructions for calculating rolling means, the learning objective of this question is to practice finding the solution.

**Question 6:**

Use a search engine (e.g., Google) or a chat LLM to find out how to calculate a rolling average in R. What search term or chat LLM prompt did you use?  What website or answer from the chat LLM did you end up using?  How much did you need to modify the code from the website or chat LLM to answer the question successfully?

**Answer 6:**

Chat LLM prompt used: "how to calculate a rolling average in R"

Answer given: "To calculate a rolling (or moving) average in R, you can use the zoo package, which provides the rollmean() function, or use filter() from the dplyr package for simpler operations. Here's how to do it using both methods:
1. Using zoo::rollmean()
First, you'll need to install and load the zoo package if you don't have it already:
r
Copy
Edit
install.packages("zoo")
library(zoo)
Then, you can use the rollmean() function to calculate a rolling average. For example, a rolling average with a window size of 5:
r
Copy
Edit
# Example data
data <- c(1, 2, 3, 4, 5, 6, 7, 8, 9, 10)
# Calculate a rolling average with a window size of 5
rolling_avg <- rollmean(data, 5, fill = NA)  # fill = NA fills the beginning with NA because of missing values
# Print the result
print(rolling_avg)
2. Using dplyr::filter() (Convolution Method)
Alternatively, you can use filter() from dplyr to calculate a rolling average manually by applying a simple moving average filter:
r
Copy
Edit
library(dplyr)
# Example data
data <- c(1, 2, 3, 4, 5, 6, 7, 8, 9, 10)
# Calculate a rolling average with a window size of 5
rolling_avg <- filter(data, rep(1/5, 5), sides = 2)
# Print the result
print(rolling_avg)
Key Points:
Window Size: The window size (5 in these examples) determines how many values are averaged in each calculation.
fill = NA in rollmean() or sides = 2 in filter() handles the edges where the window cannot be applied (such as at the beginning or end of the series)."

This code worked for me (the zoo package), and the only thing I had to modify was the data name.
```{r}
install.packages("zoo", repos = "https://cloud.r-project.org/")
library(zoo)
```

```{r}
rolling_avg <- rollmean(temp, k = 5, fill = NA)
```

**Question 7:**

- What is the meaning of "5-year average" vs. "annual average"?
- Create a data frame from the annual temperature anomaly data (from Question 4) with three new columns: 5-year running averages, 10-year running averages, and 20-year running averages.

**Answer 7:**
Five-year average refers to the average over a five-year period, where annual average is just for one year.

```{r}
new_df <- data.frame( 
  year = temp$year,
  rolling_5year = rollmean(temp$lowess_5, k = 5, fill = NA, align = "center"),
  rolling_10year = rollmean(temp$lowess_5, k = 10, fill = NA, align = "center"),
  rolling_20year = rollmean(temp$lowess_5, k = 20, fill = NA, align = "center")
)
```
**Question 8:**

Plot the different averages on the *same plot* and describe what differences you see and why.  

**Answer 8:**
While the general trend for each line is very similar, the main differences between the lines is the amount of fluctuation. The red, or 5-year line, fluctuates the most because it takes averages over a shorter period of time, while the blue, or 20-year line, fluctuates the least (is the smoothest), because it takes averages over the largest period of time.

```{r}
ggplot(new_df, aes(x = year)) +
  geom_line(aes(y = rolling_5year), color = "red") +
  geom_line(aes(y = rolling_10year), color = "yellow") +  
  geom_line(aes(y = rolling_20year), color = "blue") +
  labs(title = "5, 10, and 20 Year Average of Global Mean Temperature Anomalies", 
       x = "Year",
       y = "Global Mean Temperature Anomalies")
```

**Question 9:**

By examining the data here, what evidence do you find or not find for such a pause? 

**Answer 9:**
This graph does not support the theory of a "pause" in global warming since 1998, as previously theorized. According to this graph, global mean temperature anomalies have actually been increasing in size since 1998, not decreasing.

## Longer term trends in CO2 Records

When analyzing Earth’s climate, it is important to remember that Earth is 4.54 billion years old. Our analyses so far have only looked at recent history. How can we compare the recent data to prehistoric times? Are the current rates of change similar or different from those the earth has experienced in the past? To explore this, we can use data from ice cores drilled at the poles. 

Hundreds of ice cores have been extracted from polar ice because they contain valuable data on atmospheric chemistry over pre-historic times. These valuable data exist in tiny air bubbles trapped in the ice. These air bubbles contain the same gases in the same ratios as the atmosphere at the time when the ice formed. The data you will analyze today are from ice cores extracted from the Vostok research station in Antarctica. As you have probably assumed, the depth of the ice core is related to how old the ice is; deep ice is older. There are two other variables that you will be analyzing from the ice cores.  You will analyze CO2 concentration, which has been measured from air bubbles trapped in the ice. We can use these data to see what rates of change were like during this pre-historic period, during which human activity was minimal. 

[Ice core data](https://data.ess-dive.lbl.gov/view/doi%3A10.3334%2FCDIAC%2FATG.009):

Vostok Core, back to 400,000 years before the present day 

- Description of data set: <https://data.ess-dive.lbl.gov/view/doi%3A10.3334%2FCDIAC%2FATG.009>
- data: <https://data.ess-dive.lbl.gov/catalog/d1/mn/v2/object/ess-dive-457358fdc81d3a5-20180726T203952542>

You will use this code to download the data to your computer.

```{r}
download.file("https://data.ess-dive.lbl.gov/catalog/d1/mn/v2/object/ess-dive-457358fdc81d3a5-20180726T203952542",
              destfile = "vostok.icecore.co2")
```

You can click on the file in your Files pane to view it before reading into R.

**Question 10:**

The broad question is: how do recent atmospheric CO2 levels compare to historical levels?

Your answer to Question 10 is going to be a mix of code chunks and text that you put below in "Answer 10:"

- Describe the data set: what are the columns and units? Where do the numbers come from? 
- What is the temporal resolution of the data? 
- Read in and prepare data for analysis.   
- Reverse the ordering to create a chronological record so that each measurement is associcated with calender year.
- Plot data.  
- Combine this time series with the Mauna Loa data (the Warm-up exercise in this assignment).  You will use "bind_rows()".
- Plot the combined data. (the most recent time period must be on the right side of the plot).        
- Describe your conclusions to the question "How do recent atmospheric CO2 levels compare to historical levels?" using your plot as supporting evidence.   

**Answer 10:**
The columns are Depth (meters), Age of the ice (year BP), Mean age of the air (year BP), and CO2 Concentration (parts per million by volume). This data comes from thr Vostok Ice Core, and the labs Laboratoire de Glaciologie et de Geophysique de l'Environnement, 38402 Saint Martin d'Heres Cedex, France and
Arctic and Antarctic Research Institute Beringa Street 38 St. Petersburg 199226, Russia.             

For temporal resolution, this data set was from 2003, but the data is from 419328 to 5679 years before present.

```{r}
#read in and prepare the data for analysis
ice_core <- read_table("https://data.ess-dive.lbl.gov/catalog/d1/mn/v2/object/ess-dive-457358fdc81d3a5-20180726T203952542", 
                       comment = "#",
                       col_names = c("Depth(m)", "Age_of_the_ice", "Mean_age_of_air", "CO2_conc"), 
                       skip = 21,
                       na = c("-1", "-99.99"))
ice_core

```


```{r}
#reverse the ordering to create a chronological record so that each measurement is associated with calender year.

ice_core_sorted <- ice_core |>
  mutate(calendar_year = 2003 - Age_of_the_ice)


```

```{r}
#plot the data

ggplot(ice_core_sorted, aes(x = calendar_year, y = CO2_conc)) +
 geom_line()+
  labs(title = "CO2 Concentration from Ice Core",
       x = "Calendar Year", 
       y = "CO2 Concentration (ppmv)")
```

```{r}
#Combine this time series with the Mauna Loa data (the Warm-up exercise in this assignment).  You will use "bind_rows()".
co2 <- co2 |>
  rename(CO2_conc = monthly_average)

co2 <- co2 |>
  rename(calendar_year = year)

combined_series <- bind_rows(
  ice_core_sorted |>
    select(calendar_year, CO2_conc),
  co2 |>
    select(calendar_year, CO2_conc))
```

```{r}
#Plot the combined data. (the most recent time period must be on the right side of the plot).   
ggplot(combined_series, aes(x = calendar_year, y = CO2_conc)) +
 geom_line()+
  labs(title = "CO2 Concentration over Time",
       x = "Calendar Year", 
       y = "CO2 Concentration (ppmv)")

```
This graph demonstrates that current atmospheric CO2 levels are signifigantly higher than historical levels. The ice core data shows that CO2 levels have always fluctuated, but when combined with the Mauna Loa data we see that recent fluctuations have far bypassed historical ones. The highest peak CO2 concentration for the ice core data is 300 ppmv, but for the present data it is over 425 ppmv.

# Render and committing

Remember to Render your document as HTML and comment+push to GitHub your code and rendered HTML that was created when you knitted the document.  Your GitHub repository should have multiple commits with informative commit messages.

# Attribution

Include citation of any AI-generated assistance or discussion with classmates (per policy in syllabus). Proper documentation of AI-generated assistance includes the prompt, the source (e.g., ChatGPT), and the significant parts of the response.  Proper documentation of discussion with classmates include listing their names and the components discussed.  

For question 7 I asked ChatGPT "how to create a new data frame in r". The response I got was this:
"To create a new data frame in R, you can use the data.frame() function. Here's the basic syntax for creating a new data frame:

Example:
r
Copy
Edit
# Create a new data frame with sample data
new_df <- data.frame(
  year = c(2000, 2001, 2002, 2003, 2004),
  temperature_anomaly = c(0.4, 0.5, 0.6, 0.7, 0.8),
  region = c("Global", "Global", "Global", "Global", "Global")
)

# Print the data frame
print(new_df)"

